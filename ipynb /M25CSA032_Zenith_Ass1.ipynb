{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "R7sIfSXJwgW_",
      "metadata": {
        "id": "R7sIfSXJwgW_"
      },
      "source": [
        "# 1a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "wYNigAsVwgXA",
      "metadata": {
        "id": "wYNigAsVwgXA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, random_split, ConcatDataset\n",
        "from torchvision.models import resnet18, resnet50\n",
        "import argparse\n",
        "import os\n",
        "import time\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--dataset', type=str, required=True, choices=['MNIST', 'FashionMNIST'])\n",
        "parser.add_argument('--model', type=str, required=True, choices=['resnet18', 'resnet50'])\n",
        "parser.add_argument('--batch_size', type=int, required=True)\n",
        "parser.add_argument('--optimizer', type=str, required=True, choices=['SGD', 'Adam'])\n",
        "parser.add_argument('--lr', type=float, required=True)\n",
        "parser.add_argument('--epochs', type=int, default=4)\n",
        "parser.add_argument('--pin_memory', type=str, default='True', choices=['True', 'False'])\n",
        "args = parser.parse_args()\n",
        "\n",
        "use_pin_mem = True if args.pin_memory == 'True' else False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=3),\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "data_path = './data'\n",
        "\n",
        "if args.dataset == 'MNIST':\n",
        "    d1 = torchvision.datasets.MNIST(root=data_path, train=True, download=True, transform=transform)\n",
        "    d2 = torchvision.datasets.MNIST(root=data_path, train=False, download=True, transform=transform)\n",
        "else:\n",
        "    d1 = torchvision.datasets.FashionMNIST(root=data_path, train=True, download=True, transform=transform)\n",
        "    d2 = torchvision.datasets.FashionMNIST(root=data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "full_dataset = ConcatDataset([d1, d2])\n",
        "total_size = len(full_dataset)\n",
        "train_size = int(0.7 * total_size)\n",
        "val_size = int(0.1 * total_size)\n",
        "test_size = total_size - train_size - val_size\n",
        "\n",
        "train_set, val_set, test_set = random_split(full_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=args.batch_size, shuffle=True, pin_memory=use_pin_mem, num_workers=2)\n",
        "val_loader = DataLoader(val_set, batch_size=args.batch_size, shuffle=False, pin_memory=use_pin_mem, num_workers=2)\n",
        "test_loader = DataLoader(test_set, batch_size=args.batch_size, shuffle=False, pin_memory=use_pin_mem, num_workers=2)\n",
        "\n",
        "if args.model == 'resnet18':\n",
        "    model = resnet18(pretrained=False, num_classes=10)\n",
        "else:\n",
        "    model = resnet50(pretrained=False, num_classes=10)\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "if args.optimizer == 'SGD':\n",
        "    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=0.9)\n",
        "else:\n",
        "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
        "\n",
        "scaler = torch.cuda.amp.GradScaler()\n",
        "print(f\"Running: {args.dataset} {args.model} BS={args.batch_size} Opt={args.optimizer} LR={args.lr} Ep={args.epochs}\")\n",
        "\n",
        "start_time = time.time()\n",
        "output_dir = \"results_final\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "summary_file = os.path.join(output_dir, \"q1_final_report.csv\")\n",
        "if not os.path.isfile(summary_file):\n",
        "    with open(summary_file, \"w\") as f:\n",
        "        f.write(\"Dataset,Model,BatchSize,Optimizer,LR,Epochs,PinMem,TestAccuracy,TotalTime\\n\")\n",
        "\n",
        "curve_file = os.path.join(output_dir, f\"curve_{args.dataset}_{args.model}_{args.optimizer}_{args.lr}.csv\")\n",
        "with open(curve_file, \"w\") as f:\n",
        "    f.write(\"Dataset,Model,BatchSize,Optimizer,LR,Epochs,Epoch,TrainLoss,ValAcc\\n\")\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    ep_start = time.time()\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with torch.cuda.amp.autocast():\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    val_acc = 100 * correct / total\n",
        "    epoch_time = time.time() - ep_start\n",
        "    total_time = time.time() - start_time\n",
        "\n",
        "    with open(curve_file, \"a\") as f:\n",
        "        f.write(f\"{args.dataset},{args.model},{args.batch_size},{args.optimizer},{args.lr},{args.epochs},{epoch+1},{avg_loss:.4f},{val_acc:.2f}\\n\")\n",
        "\n",
        "    print(f\"Ep {epoch+1}/{args.epochs} | Loss: {avg_loss:.4f} | ValAcc: {val_acc:.2f}% | Time: {epoch_time:.2f}s\")\n",
        "\n",
        "model.eval()\n",
        "correct_test = 0\n",
        "total_test = 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_test += labels.size(0)\n",
        "        correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "test_acc = 100 * correct_test / total_test\n",
        "print(f\"TEST ACCURACY: {test_acc:.2f}%\")\n",
        "\n",
        "with open(summary_file, \"a\") as f:\n",
        "    f.write(f\"{args.dataset},{args.model},{args.batch_size},{args.optimizer},{args.lr},{args.epochs},{args.pin_memory},{test_acc:.2f},{total_time:.2f}\\n\")\n",
        "\n",
        "tracker_path = os.path.join(output_dir, f\"best_acc_tracker_{args.dataset}.txt\")\n",
        "current_best = 0.0\n",
        "\n",
        "if os.path.exists(tracker_path):\n",
        "    with open(tracker_path, \"r\") as f:\n",
        "        try:\n",
        "            current_best = float(f.read().strip())\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "if test_acc > current_best:\n",
        "    with open(tracker_path, \"w\") as f:\n",
        "        f.write(str(test_acc))\n",
        "    save_path = os.path.join(output_dir, f\"best_model_{args.dataset}.pth\")\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f\"New best model saved for {args.dataset}: {test_acc:.2f}%\")\n",
        "\n",
        "    all_preds = []\n",
        "    all_labels = []\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            \n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.numpy())\n",
        "\n",
        "    cm = confusion_matrix(all_labels, all_preds)\n",
        "    \n",
        "    cm_file = os.path.join(output_dir, f\"confusion_matrix_{args.dataset}_best.csv\")\n",
        "    \n",
        "    if args.dataset == 'MNIST':\n",
        "        classes = [str(i) for i in range(10)]\n",
        "    else:\n",
        "        classes = ['T-shirt', 'Trouser', 'Pullover', 'Dress', 'Coat', \n",
        "                   'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "                   \n",
        "    df_cm = pd.DataFrame(cm, index=classes, columns=classes)\n",
        "    df_cm.to_csv(cm_file)\n",
        "    print(f\"Confusion Matrix saved to: {cm_file}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "_PcExWALwgXB",
      "metadata": {
        "id": "_PcExWALwgXB"
      },
      "source": [
        "### Q1(a) Execution Logs\n",
        "\n",
        "```text\n",
        "Running: MNIST resnet18 BS=16 Opt=SGD LR=0.001 Ep=4\n",
        "Ep 1/4 | Loss: 0.1480 | ValAcc: 98.69% | Time: 49.80s\n",
        "Ep 2/4 | Loss: 0.0396 | ValAcc: 98.81% | Time: 41.58s\n",
        "Ep 3/4 | Loss: 0.0225 | ValAcc: 98.96% | Time: 41.66s\n",
        "Ep 4/4 | Loss: 0.0139 | ValAcc: 99.09% | Time: 41.50s\n",
        "TEST ACCURACY: 99.24%\n",
        "New best model saved for MNIST: 99.24%\n",
        "\n",
        "Running: MNIST resnet18 BS=16 Opt=SGD LR=0.0001 Ep=4\n",
        "Ep 1/4 | Loss: 0.4686 | ValAcc: 96.14% | Time: 43.26s\n",
        "Ep 2/4 | Loss: 0.1198 | ValAcc: 97.79% | Time: 32.34s\n",
        "Ep 3/4 | Loss: 0.0780 | ValAcc: 98.26% | Time: 44.06s\n",
        "Ep 4/4 | Loss: 0.0573 | ValAcc: 98.44% | Time: 38.00s\n",
        "TEST ACCURACY: 98.44%\n",
        "\n",
        "Running: FashionMNIST resnet50 BS=32 Opt=Adam LR=0.001 Ep=10\n",
        "Ep 1/10 | Loss: 0.5572 | ValAcc: 86.70% | Time: 79.35s\n",
        "Ep 2/10 | Loss: 0.3904 | ValAcc: 88.96% | Time: 77.39s\n",
        "Ep 3/10 | Loss: 0.2942 | ValAcc: 88.61% | Time: 78.63s\n",
        "Ep 4/10 | Loss: 0.2818 | ValAcc: 90.13% | Time: 78.68s\n",
        "Ep 5/10 | Loss: 0.2529 | ValAcc: 90.11% | Time: 78.65s\n",
        "Ep 6/10 | Loss: 0.4414 | ValAcc: 84.89% | Time: 78.00s\n",
        "Ep 7/10 | Loss: 0.4037 | ValAcc: 85.56% | Time: 72.00s\n",
        "Ep 8/10 | Loss: 0.3766 | ValAcc: 86.37% | Time: 71.44s\n",
        "Ep 9/10 | Loss: 0.3540 | ValAcc: 85.80% | Time: 70.90s\n",
        "Ep 10/10 | Loss: 0.3320 | ValAcc: 87.16% | Time: 70.88s\n",
        "TEST ACCURACY: 87.34%\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "gqLhKu_xwgXC",
      "metadata": {
        "id": "gqLhKu_xwgXC"
      },
      "source": [
        "# 1b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ZWITzCHswgXC",
      "metadata": {
        "id": "ZWITzCHswgXC"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import argparse\n",
        "import numpy as np\n",
        "from sklearn import svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--dataset', type=str, required=True, choices=['MNIST', 'FashionMNIST'])\n",
        "parser.add_argument('--kernel', type=str, required=True, choices=['poly', 'rbf'])\n",
        "args = parser.parse_args()\n",
        "\n",
        "print(f\"Processing {args.dataset} with {args.kernel} kernel...\")\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()])\n",
        "data_path = './data'\n",
        "\n",
        "if args.dataset == 'MNIST':\n",
        "    train_set = torchvision.datasets.MNIST(root=data_path, train=True, download=True, transform=transform)\n",
        "    test_set = torchvision.datasets.MNIST(root=data_path, train=False, download=True, transform=transform)\n",
        "else:\n",
        "    train_set = torchvision.datasets.FashionMNIST(root=data_path, train=True, download=True, transform=transform)\n",
        "    test_set = torchvision.datasets.FashionMNIST(root=data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "X_train = train_set.data.numpy().reshape(-1, 28*28) / 255.0\n",
        "y_train = train_set.targets.numpy()\n",
        "\n",
        "X_test = test_set.data.numpy().reshape(-1, 28*28) / 255.0\n",
        "y_test = test_set.targets.numpy()\n",
        "\n",
        "clf = svm.SVC(kernel=args.kernel)\n",
        "\n",
        "t0 = time.time()\n",
        "clf.fit(X_train, y_train)\n",
        "train_time = (time.time() - t0) * 1000\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred) * 100\n",
        "\n",
        "print(f\"Done. Acc: {acc:.2f}%, Time: {train_time:.2f}ms\")\n",
        "\n",
        "if not os.path.exists(\"results_revised\"):\n",
        "    os.makedirs(\"results_revised\")\n",
        "\n",
        "csv_path = \"results_revised/svm_results.csv\"\n",
        "if not os.path.isfile(csv_path):\n",
        "    with open(csv_path, \"w\") as f:\n",
        "        f.write(\"Dataset,Kernel,Accuracy,Time_ms\\n\")\n",
        "\n",
        "with open(csv_path, \"a\") as f:\n",
        "    f.write(f\"{args.dataset},{args.kernel},{acc:.2f},{train_time:.2f}\\n\")\n",
        "\n",
        "best_tracker = f\"results_revised/best_svm_{args.dataset}.txt\"\n",
        "current_best = 0.0\n",
        "if os.path.exists(best_tracker):\n",
        "    with open(best_tracker, \"r\") as f:\n",
        "        try:\n",
        "            current_best = float(f.read().strip())\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "if acc > current_best:\n",
        "    with open(best_tracker, \"w\") as f:\n",
        "        f.write(str(acc))\n",
        "    joblib.dump(clf, f\"results_revised/best_svm_{args.dataset}.pkl\")\n",
        "    print(f\"New Best SVM: {acc:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1rM7_zGewgXC",
      "metadata": {
        "id": "1rM7_zGewgXC"
      },
      "source": [
        "### Q1(b) Execution Logs\n",
        "\n",
        "```text\n",
        "Processing MNIST with poly kernel...\n",
        "Done. Acc: 97.71%, Time: 169357.63ms\n",
        "New Best SVM: 97.71%\n",
        "\n",
        "Processing MNIST with rbf kernel...\n",
        "Done. Acc: 97.92%, Time: 162137.42ms\n",
        "New Best SVM: 97.92%\n",
        "\n",
        "Processing FashionMNIST with poly kernel...\n",
        "Done. Acc: 86.30%, Time: 279310.38ms\n",
        "\n",
        "Processing FashionMNIST with rbf kernel...\n",
        "Done. Acc: 88.28%, Time: 222573.50ms\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4xyag4kOwgXC",
      "metadata": {
        "id": "4xyag4kOwgXC"
      },
      "source": [
        "# 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7uqf0yKGwgXC",
      "metadata": {
        "id": "7uqf0yKGwgXC"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet18, resnet50\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def count_flops(model, input_size=(1, 3, 64, 64), device='cpu'):\n",
        "    flops = 0\n",
        "    def hook(mod, inp, out):\n",
        "        nonlocal flops\n",
        "        if isinstance(mod, nn.Conv2d):\n",
        "            in_c = mod.in_channels\n",
        "            out_c = mod.out_channels\n",
        "            k_h, k_w = mod.kernel_size\n",
        "            b, c, h, w = out.shape\n",
        "            ops = 2 * in_c * k_h * k_w * out_c * h * w\n",
        "            if mod.bias is not None:\n",
        "                ops += out_c * h * w\n",
        "            flops += (ops // b)\n",
        "        elif isinstance(mod, nn.Linear):\n",
        "            in_f = mod.in_features\n",
        "            out_f = mod.out_features\n",
        "            ops = 2 * in_f * out_f\n",
        "            if mod.bias is not None:\n",
        "                ops += out_f\n",
        "            flops += ops\n",
        "\n",
        "    hooks = []\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            hooks.append(m.register_forward_hook(hook))\n",
        "\n",
        "    dummy = torch.randn(input_size).to(device)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        model(dummy)\n",
        "\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "    return flops / 1e9\n",
        "\n",
        "def train_model(device_str, model_name, optimizer_name, epochs=10):\n",
        "    print(f\"Running: {device_str} | {model_name} | {optimizer_name}\")\n",
        "\n",
        "    device = torch.device(device_str)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    data_path = './data'\n",
        "    train_set = torchvision.datasets.FashionMNIST(root=data_path, train=True, download=True, transform=transform)\n",
        "    test_set = torchvision.datasets.FashionMNIST(root=data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True, pin_memory=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False, pin_memory=True, num_workers=2)\n",
        "\n",
        "    if model_name == 'resnet18':\n",
        "        model = resnet18(pretrained=False, num_classes=10)\n",
        "    else:\n",
        "        model = resnet50(pretrained=False, num_classes=10)\n",
        "\n",
        "    model = model.to(device)\n",
        "    gflops = count_flops(model, device=device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if optimizer_name == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    else:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_train = time.time()\n",
        "\n",
        "    output_dir = \"results_q2\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    curve_file = os.path.join(output_dir, f\"curve_q2_{device_str}_{model_name}_{optimizer_name}.csv\")\n",
        "    with open(curve_file, \"w\") as f:\n",
        "        f.write(\"Device,Model,Optimizer,Epoch,TrainLoss,TestAcc\\n\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        ep_start = time.time()\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = 100 * correct / total\n",
        "        ep_time = time.time() - ep_start\n",
        "\n",
        "        print(f\"  Ep {epoch+1}/{epochs} | Time: {ep_time:.2f}s | Loss: {avg_loss:.4f} | Acc: {test_acc:.2f}%\")\n",
        "        with open(curve_file, \"a\") as f:\n",
        "            f.write(f\"{device_str},{model_name},{optimizer_name},{epoch+1},{avg_loss:.4f},{test_acc:.2f}\\n\")\n",
        "\n",
        "    total_train_time = time.time() - start_train\n",
        "\n",
        "    summary_file = os.path.join(output_dir, \"q2_final_report.csv\")\n",
        "    if not os.path.isfile(summary_file):\n",
        "        with open(summary_file, \"w\") as f:\n",
        "            f.write(\"Device,Model,Optimizer,TotalTimeSec,FinalAcc,GFLOPs\\n\")\n",
        "\n",
        "    with open(summary_file, \"a\") as f:\n",
        "        f.write(f\"{device_str},{model_name},{optimizer_name},{total_train_time:.2f},{test_acc:.2f},{gflops:.4f}\\n\")\n",
        "\n",
        "    tracker_file = os.path.join(output_dir, f\"best_acc_q2_{device_str}.txt\")\n",
        "    current_best = 0.0\n",
        "    if os.path.exists(tracker_file):\n",
        "        try:\n",
        "            with open(tracker_file, \"r\") as f:\n",
        "                current_best = float(f.read().strip())\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    if test_acc > current_best:\n",
        "        with open(tracker_file, \"w\") as f:\n",
        "            f.write(str(test_acc))\n",
        "        save_name = os.path.join(output_dir, f\"best_model_q2_{device_str}.pth\")\n",
        "        torch.save(model.state_dict(), save_name)\n",
        "        print(f\"  New Best Model Saved for {device_str}!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    configs = [\n",
        "        ('cpu', 'resnet18', 'SGD'),\n",
        "        ('cpu', 'resnet18', 'Adam'),\n",
        "        ('cpu', 'resnet50', 'SGD'),\n",
        "        ('cpu', 'resnet50', 'Adam'),\n",
        "        ('cuda', 'resnet18', 'SGD'),\n",
        "        ('cuda', 'resnet18', 'Adam'),\n",
        "        ('cuda', 'resnet50', 'SGD'),\n",
        "        ('cuda', 'resnet50', 'Adam')\n",
        "    ]\n",
        "\n",
        "    print(\"Starting Q2 Benchmark...\")\n",
        "    for dev, mod, opt in configs:\n",
        "        if dev == 'cuda' and not torch.cuda.is_available():\n",
        "            print(\"Skipping CUDA (not available)\")\n",
        "            continue\n",
        "        train_model(dev, mod, opt, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jhKdPuJSwgXC",
      "metadata": {
        "id": "jhKdPuJSwgXC"
      },
      "source": [
        "### Q2 Execution Logs\n",
        "\n",
        "```text\n",
        "Starting Q2 Benchmark...\n",
        "Running: CPU | resnet18 | SGD\n",
        "  Ep 1/10 | Time: 274.14s | Loss: 0.4254 | Acc: 87.85%\n",
        "  Ep 2/10 | Time: 272.25s | Loss: 0.2694 | Acc: 90.27%\n",
        "  Ep 3/10 | Time: 272.06s | Loss: 0.2166 | Acc: 90.99%\n",
        "  ...\n",
        "  Ep 10/10 | Time: 272.42s | Loss: 0.0685 | Acc: 91.61%\n",
        "\n",
        "Running: CUDA | resnet18 | Adam\n",
        "  Ep 1/10 | Time: 78.05s | Loss: 0.4012 | Acc: 89.12%\n",
        "  ...\n",
        "  Ep 10/10 | Time: 77.69s | Loss: 0.0685 | Acc: 92.83%\n",
        "  New Best Model Saved for cuda!\n",
        "\n",
        "Running: CUDA | resnet50 | SGD\n",
        "  Ep 1/10 | Time: 135.04s | Loss: 0.6541 | Acc: 86.15%\n",
        "  ...\n",
        "  Ep 10/10 | Time: 126.51s | Loss: 0.1296 | Acc: 91.17%\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j3TTCQOMwgXC",
      "metadata": {
        "id": "j3TTCQOMwgXC"
      },
      "source": [
        "# 2_resnet34"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "yXE_99aEwgXD",
      "metadata": {
        "id": "yXE_99aEwgXD"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import resnet34\n",
        "from torch.utils.data import DataLoader\n",
        "import time\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def count_flops(model, input_size=(1, 3, 64, 64), device='cpu'):\n",
        "    flops = 0\n",
        "    def hook(mod, inp, out):\n",
        "        nonlocal flops\n",
        "        if isinstance(mod, nn.Conv2d):\n",
        "            in_c = mod.in_channels\n",
        "            out_c = mod.out_channels\n",
        "            k_h, k_w = mod.kernel_size\n",
        "            b, c, h, w = out.shape\n",
        "            ops = 2 * in_c * k_h * k_w * out_c * h * w\n",
        "            if mod.bias is not None:\n",
        "                ops += out_c * h * w\n",
        "            flops += (ops // b)\n",
        "        elif isinstance(mod, nn.Linear):\n",
        "            in_f = mod.in_features\n",
        "            out_f = mod.out_features\n",
        "            ops = 2 * in_f * out_f\n",
        "            if mod.bias is not None:\n",
        "                ops += out_f\n",
        "            flops += ops\n",
        "\n",
        "    hooks = []\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
        "            hooks.append(m.register_forward_hook(hook))\n",
        "\n",
        "    dummy = torch.randn(input_size).to(device)\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        model(dummy)\n",
        "\n",
        "    for h in hooks:\n",
        "        h.remove()\n",
        "    return flops / 1e9\n",
        "\n",
        "def train_model(device_str, model_name, optimizer_name, epochs=10):\n",
        "    print(f\"Running: {device_str} | {model_name} | {optimizer_name}\")\n",
        "\n",
        "    device = torch.device(device_str)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Grayscale(num_output_channels=3),\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    data_path = './data'\n",
        "    train_set = torchvision.datasets.FashionMNIST(root=data_path, train=True, download=True, transform=transform)\n",
        "    test_set = torchvision.datasets.FashionMNIST(root=data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "    train_loader = DataLoader(train_set, batch_size=64, shuffle=True, pin_memory=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_set, batch_size=64, shuffle=False, pin_memory=True, num_workers=2)\n",
        "\n",
        "    if model_name == 'resnet34':\n",
        "        model = resnet34(pretrained=False, num_classes=10)\n",
        "\n",
        "    model = model.to(device)\n",
        "    gflops = count_flops(model, device=device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    if optimizer_name == 'SGD':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "    else:\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    start_train = time.time()\n",
        "\n",
        "    output_dir = \"results_q2\"\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "    curve_file = os.path.join(output_dir, f\"curve_q2_{device_str}_{model_name}_{optimizer_name}.csv\")\n",
        "    with open(curve_file, \"w\") as f:\n",
        "        f.write(\"Device,Model,Optimizer,Epoch,TrainLoss,TestAcc\\n\")\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        ep_start = time.time()\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_acc = 100 * correct / total\n",
        "        ep_time = time.time() - ep_start\n",
        "\n",
        "        print(f\"  Ep {epoch+1}/{epochs} | Time: {ep_time:.2f}s | Loss: {avg_loss:.4f} | Acc: {test_acc:.2f}%\")\n",
        "        with open(curve_file, \"a\") as f:\n",
        "            f.write(f\"{device_str},{model_name},{optimizer_name},{epoch+1},{avg_loss:.4f},{test_acc:.2f}\\n\")\n",
        "\n",
        "    total_train_time = time.time() - start_train\n",
        "\n",
        "    summary_file = os.path.join(output_dir, \"q2_final_report.csv\")\n",
        "    if not os.path.isfile(summary_file):\n",
        "        with open(summary_file, \"w\") as f:\n",
        "            f.write(\"Device,Model,Optimizer,TotalTimeSec,FinalAcc,GFLOPs\\n\")\n",
        "\n",
        "    with open(summary_file, \"a\") as f:\n",
        "        f.write(f\"{device_str},{model_name},{optimizer_name},{total_train_time:.2f},{test_acc:.2f},{gflops:.4f}\\n\")\n",
        "\n",
        "    tracker_file = os.path.join(output_dir, f\"best_acc_q2_{device_str}_res34.txt\")\n",
        "    current_best = 0.0\n",
        "    if os.path.exists(tracker_file):\n",
        "        try:\n",
        "            with open(tracker_file, \"r\") as f:\n",
        "                current_best = float(f.read().strip())\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    if test_acc > current_best:\n",
        "        with open(tracker_file, \"w\") as f:\n",
        "            f.write(str(test_acc))\n",
        "        save_name = os.path.join(output_dir, f\"best_model_q2_{device_str}_res34.pth\")\n",
        "        torch.save(model.state_dict(), save_name)\n",
        "        print(f\"  New Best Model Saved for {device_str}!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    configs = [\n",
        "        ('cpu', 'resnet34', 'SGD'),\n",
        "        ('cpu', 'resnet34', 'Adam'),\n",
        "        ('cuda', 'resnet34', 'SGD'),\n",
        "        ('cuda', 'resnet34', 'Adam')\n",
        "    ]\n",
        "\n",
        "    print(\"Starting Q2 Benchmark (ResNet34 Only)...\")\n",
        "    for dev, mod, opt in configs:\n",
        "        if dev == 'cuda' and not torch.cuda.is_available():\n",
        "            print(\"Skipping CUDA (not available)\")\n",
        "            continue\n",
        "        train_model(dev, mod, opt, epochs=10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jhE9Yh9WwgXD",
      "metadata": {
        "id": "jhE9Yh9WwgXD"
      },
      "source": [
        "### Q2 (ResNet-34) Execution Logs\n",
        "\n",
        "```text\n",
        "Starting Q2 Benchmark (ResNet34 Only)...\n",
        "Running: CPU | resnet34 | SGD\n",
        "  Ep 1/10 | Time: 469.34s | Loss: 0.4620 | Acc: 88.63%\n",
        "  Ep 2/10 | Time: 467.68s | Loss: 0.2841 | Acc: 90.20%\n",
        "  ...\n",
        "  Ep 10/10 | Time: 557.22s | Loss: 0.0786 | Acc: 92.51%\n",
        "  New Best Model Saved for cpu!\n",
        "\n",
        "Running: CUDA | resnet34 | SGD\n",
        "  Ep 1/10 | Time: 111.50s | Loss: 0.4796 | Acc: 88.23%\n",
        "  Ep 2/10 | Time: 109.30s | Loss: 0.2904 | Acc: 89.56%\n",
        "  ...\n",
        "  Ep 5/10 | Time: 110.30s | Loss: 0.1698 | Acc: 90.7%\n",
        "```"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
